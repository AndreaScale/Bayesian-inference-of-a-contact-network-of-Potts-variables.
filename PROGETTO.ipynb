{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To be done:\n",
    "- DONE (magari può essere fatto meglio, ma non ho voglia e non saprei come) Commento grafici punto 4\n",
    "- DONE (nel senso che era stupido:)Commento su perchè non sampliamo direttamente dalla posterior nel punto 3 (non sono sicura su questo, samplare dalla posterior sarebbe finalizzato ad utilizzare un diverso stimatore bayesiano (la media della posterior) ho paura che aggiungendo anche questo si vada un po' fuori strada)\n",
    "- DONE \n",
    "Tutti gli esempi - TUTTI.. ne ho guardati un tot - usano la sommatoria nella likelihood solo per $i<j$ e per i termini uguali considerano solo l'influenza di un campo esterno... ce ne freghiamo altamente o facciamo un commento del tipo \"a parer nostro l'esponente della likelihood sarebbe dovuto essere ..... , ma ci atteniamo in ogni caso al testo dell'esercizio\"?\n",
    "\n",
    "- Especially per il mio amico matematico, possiamo dire che la log-likelihood e il log della posterior sono funzioni concave? Perchè in teoria è una cosa importante per poter usare il metodo del gradiente.\n",
    "(dovrebbe esserlo)\n",
    "\n",
    "- Valutare la bontà del punto 5, non so bene se quel che ho fatto va bene :()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are given $N=5$ variables and $M$ observations. The observations are:\n",
    "\n",
    "$$\\textbf{x}^{(m)}=(x_1^{(m)},\\dots ,x_N^{(m)})$$\n",
    "\n",
    "Where $x_i^{(m)}\\in\\{1,\\dots,q\\}$ are categorical variable. In order to model the interaction between these variables we use the Potts model. Let $J_{ij}\\in \\R^{q\\times q}$ be the coupling matrix for the variables $i$ and $j$ having respectevly colors $a$ and $b$, i.e. if $J_{ij}(a,b)\\neq0$ then the variables interact (accordingly to the sign) while if $J_{ij}(a,b)\\sim0$ they do not. \n",
    "\n",
    "We consider the model:\n",
    "\n",
    "$$P\\left(x\\,|\\,J\\right)=\\frac{1}{Z}e^{\\sum_{ij}\\sum_{ab}J_{ij}(a,b)\\delta_{(x_i,a)}\\delta_{(x_j,b)}}$$\n",
    "\n",
    "Where the exponent represent (minus) the \"energy\" of the model and the partition function\n",
    "\n",
    "$$Z\\left(J\\right) = \\sum_{x} e^{\\sum_{i,j}\\sum_{ab}J_{ij}(a,b)\\delta_{(x_i,a)}\\delta_{(x_j,b)}}$$\n",
    "\n",
    "is generally intractable as it requires to sum over $q^M$ states of the variables.\n",
    "\n",
    "<font color = \"yellow\">Since we are driven to interpret the exponent of the likelihood function as a measure of the energy of the model, we actually expect that its sum should have been only over the variables $i \\le j$ for $i,j=1,\\dots,N$. In fact if we consider all possible combination of the pairs $(i,j)$, we end up summing twice the interaction between $i$ and $j$ for all $i,j$ (because the interaction $(i,j)$ coincides with $(j,i)$). We also expected no interaction of a variable with itself, nevertheless we may interpret these as due to the action of an external field. Nevertheless we stick to the given definition (mainly because the data have probabibly have been generated in this framework).</font>\n",
    "\n",
    "Coming back to our task, our purpose is to infer the coupling matrix $J$. To do so we should decide which estimator will be the object of our inference. Probably the most natural one - and hence our first choice, is the maximum likelihood estimator (MLE). In a regular model, it is generally found has the value of the parameter of interest that solves the first order conditions \n",
    "\n",
    "$$\\frac{\\partial \\mathcal{L}\\left(J;\\left\\{x_i^{(m)}\\right\\}_{m=1}^{M}\\right)}{\\partial J_{i,j}(a,b)} = 0$$\n",
    "\n",
    "where\n",
    "\n",
    "$$\\mathcal{L}\\left(J;\\left\\{x_i^{(m)}\\right\\}_{m=1}^{M}\\right)=\\prod_m\\frac{1}{Z}e^{\\sum_{ij}\\sum_{ab}J_{ij}(a,b)\\delta_{(x_i^{(m)},a)}\\delta_{(x_j^{(m)},b)}}$$\n",
    "\n",
    "is the likelihood distribution of our sampling model.\n",
    "\n",
    "In general it is useful to compute the log-likelihood divided by $M$ and then its derivative with respect to each parameter $J_{ij}(a,b)$ (note indeed that this trasformation does not affect the monotonicity of the likelihood and hence the coordinates of the maximum).\n",
    "\n",
    "We obtain:\n",
    "\n",
    "$$\\mathcal{l}\\left( J ; \\{x^{(m)} \\}_{m=1}^{M} \\right) = {\\frac{1}{M}}  \\sum_{ij}\\sum_{ab}\\sum_m J_{ij}(a,b)\\delta_{(x_i^{(m)},a)}\\delta_{(x_j^{(m)},b)} - \\log\\left[ Z\\left( J\\right)\\right]$$\n",
    "\n",
    "and then:\n",
    "\n",
    "\\begin{align}\n",
    "\\frac{\\partial \\mathcal{l} \\left(J ; \\{x^{(m)} \\}_{m=1}^{M}  \\right)}{\\partial J_{i,j}(a,b)} & = {\\frac{1}{M}} \\sum_{m} \\delta_{(x_i^{(m)},a)}\\delta_{(x_j^{(m)},b)} - \\frac{1}{Z\\left( J\\right)} \\sum_{\\boldsymbol{x}} \\delta_{(x_i^{(m)},a)}\\delta_{(x_j^{(m)},b)} e^{\\sum_{i,j}\\sum_{ab}J_{ij}(a,b)\\delta_{(x_i^{(m)},a)}\\delta_{(x_j^{(m)},b)}} \\\\\n",
    "& = { < \\delta_{(x_i,a)} \\delta_{(x_j,b)} >_{\\mathrm{data}} -  < \\delta_{(x_i,a)} \\delta_{(x_j,b)} >_{\\mathrm{model}}}\n",
    "\\end{align}\n",
    "\n",
    "Now, solving directly the moment-matching conditions\n",
    "\n",
    "$$\\frac{\\partial \\mathcal{l} \\left(J ; \\{x^{(m)} \\}_{m=1}^{M}  \\right)}{\\partial J_{i,j}(a,b)}  = 0$$\n",
    "\n",
    "is a highly non-trivial numerical task, except for very peculiar forms of the coupling matrix, due to the difficulty in computing averages over the model distribution. Instead we rely on a flexible numerical method, known under the name of Boltzmann machine learning method, that ultimately allow us to iteratively update $J$ using a gradient ascend method.\n",
    "\n",
    "Note that the gradient ascend method can be performed thanks to the fact that the log-likelihood is a concave function, hence it has only one maximum and the gradient ascend method will numerically compute the MLE of $J$.\n",
    "\n",
    "Now, in order to design the Boltzmann machine learing scheme, it is crucial to be able to evaluate the gradient of the log-likelihood, whose explicit formula has already been computed above. The first term of the difference is easly computable, the second quite not. In order to reach our goal we can use a MCMC with Metropolis-Hastings update or Gibbs sampling. Then our iterative update of $J$ will be performed as:\n",
    "\n",
    "$$J_{i,j}^{t+1}(a,b) \\leftarrow J_{i,j}^{t}(a,b) + \\lambda_{J} \\left[ < \\delta_{(x_i,a)} \\delta_{(x_j,b)} >_{\\mathrm{data}} -  < \\delta_{(x_i,a)} \\delta_{(x_j,b)} >_{\\mathrm{model}\\left(t \\right)} \\right] $$\n",
    "\n",
    "where $\\lambda$ is an adequately chosen learning rate.\n",
    "\n",
    "The intuition underlying this update rule is that, if for example $< \\delta_{(x_i,a)} \\delta_{(x_j,b)} >_{\\mathrm{model}\\left(t \\right)}$ is larger than the corresponding value for the data, the value of $J$ should be decreased to match\n",
    "these two moments.\n",
    "\n",
    "For what concernes the MCMC with Metropolis-Hastings update:\n",
    "\n",
    "\n",
    "- We start from a uniformly randomly extracted configuration $\\boldsymbol{x}^{t = 0}$\n",
    "\n",
    "\n",
    "- As proposal distribution: extract an index $i\\in\\{1,\\dots,N\\}$ and a variable $a\\in\\{1,\\dots,q\\}$ and substitute the value of $\\delta_{(x_i^{t-1},a)}$ with its opposite ($1\\rightarrow0$, $0\\rightarrow1$)\n",
    "\n",
    "\n",
    "- Accept the move with probability:\n",
    "\n",
    "$$p_{\\rm acc} =\\min\\left[1, \\frac{q(x^{t-1}|x)\\tilde{\\pi}(x)}{q(x|x^{t-1})\\tilde{\\pi}(x^{t-1})} \\right]$$\n",
    "\n",
    "- Save many configuations and compute $<x_{i} x_{j}>_{\\mathrm{model}\\left(t\\right)}$ at $\\sim$ equilibrium \n",
    "\n",
    "We have to compute the acceptance ration in our setting. By the simmetry of the proposal distribution $q$ we have:\n",
    "\n",
    "$$\\frac{q(x^{t-1}|x)\\tilde{\\pi}(x)}{q(x|x^{t-1})\\tilde{\\pi}(x^{t-1})}=\\frac{\\tilde{\\pi}(x)}{\\tilde{\\pi}(x^{t-1})}$$\n",
    "\n",
    "We extract the index $i$ and the color $a$ (different from the actual color of $x_i$) and create the proposal $x^n$ as follows:\n",
    "\n",
    "$$x_k^n=\\begin{cases}\n",
    "x_k & k\\neq i \\\\\n",
    "a & k=i\n",
    "\\end{cases}$$\n",
    "\n",
    "Then:\n",
    "\n",
    "$$\\frac{\\tilde{\\pi}(x^n)}{\\tilde{\\pi}(x)}=\\frac{e^{\\sum_{kj}\\sum_{cb}J_{kj}(c,b)\\delta_{(x_k^n,c)}\\delta_{(x_j^n,b)}}}{e^{\\sum_{kj}\\sum_{cb}J_{kj}(c,b)\\delta_{(x_k,c)}\\delta_{(x_j,b)}}}=\\frac{e^{\\sum_{kj}J_{kj}(x_k^n,x_j^n)}}{e^{\\sum_{kj}J_{kj}(x_k,x_j)}}$$\n",
    "\n",
    "Then by definition of $x^n$ and the simmetry $J_{ij}(a,b)=J_{ji}(b,a)$ we have:\n",
    "\n",
    "$$\\sum_{k,j}J_{kj}(x_k^n,x_j^n)-\\sum_{k,j}J_{kj}(x_k,x_j)=\\sum_{k}J_{ki}(x_k^n,x_i^n)-\\sum_{k}J_{ki}(x_k,x_i)+\\sum_{j}J_{ij}(x_i^n,x_j^n)-\\sum_{j}J_{ij}(x_i,x_j)=$$\n",
    "$$2\\sum_{j\\neq i}\\left(J_{ij}(x_i^n,x_j^n)-J_{ij}(x_i,x_j)\\right)$$\n",
    "\n",
    "Finally assuming $J_{jj}=0 \\,\\forall j$ we get:\n",
    "\n",
    "$$\\frac{\\tilde{\\pi}(x^n)}{\\tilde{\\pi}(x)}=2\\sum_{j}\\left(J_{ij}(x_i^n,x_j^n)-J_{ij}(x_i,x_j)\\right)$$\n",
    "\n",
    "Finally update the parameters until convergence, when the maximum value of the gradient is smaller than a certain threshold."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before proceeding with the actual code we make some further remarks.\n",
    "\n",
    "As the core of the Boltzmann machine learning scheme corresponds to a gradient ascent dynamics for the log-likelihood, convergence towards the maximum is guaranteed, provided $\\lambda$ are diminished and eventually sent to zero to gently stop in the maximum. However, Boltzmann machine learning suffers from some drawbacks.\n",
    "\n",
    "First, as the learning dynamics is formulated in a very high-dimensional space, the log-likelihood could be extremely steep along some directions and very flat along others. Thus, a single learning rate $\\lambda$ for the couplings could be either too large, leading to overshooting along the steeper directions, or too small, yielding no parameter updates along the flat directions.\n",
    "\n",
    "This issue could in principle be solved with second-order methods, such as a generalisation of the Newton-Raphson method. However estimating the curvature matrix is quite complex and time-demanding in high dimensions.\n",
    "\n",
    "Second, Boltzmann machine learning may require massive Monte Carlo sampling, because the moments should be computed at each update step. This may arise issues since, in each Monte Carlo simulation, one can not be sure that equilibration has been realised and that the moment are correctly estimated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function metropolis_ising(x::Vector{Int64}, J::Array{Matrix{Float64}})\n",
    "\n",
    "    N = length(x)\n",
    "\n",
    "    i = rand(1:N)       # draw uniformly an index\n",
    "    c = rand(1:q-1)     # draw uniformly a color different to the current one of x[i], this is equivalent to uniformly draw a number between 1 and q-1\n",
    "                        # and then add the drawn number to the current categorical state of x[i]\n",
    "    xi_new = mod1(x[i]+c, q)\n",
    "    ΔJ = 0\n",
    "    for j in 1:N\n",
    "        if j != i  #we exclude j=i because in the first matrix J we use the proposal  \n",
    "            ΔJ += 2.0*(J[i,j][xi_new, x[j]] - J[i,j][x[i], x[j]])   # argument of the exponential given by the ratio of the target distribution\n",
    "        end\n",
    "    end\n",
    "    ΔJ += (J[i,i][xi_new, xi_new] - J[i,i][x[i], x[i]])\n",
    "    if rand() < exp(ΔJ)\n",
    "        x[i] = xi_new    # if the move is accepted, we update it\n",
    "    end\n",
    "    return x\n",
    "\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function compute_stats(data::Matrix{Int64}, M::Int64; q = 4) #M is the number of observations considered\n",
    "    N = size(data, 2)\n",
    "    if M>size(data, 1)\n",
    "        print(\"Too large M\")\n",
    "    else\n",
    "        sij = Array{Matrix{Float64}}(undef, N, N) \n",
    "        for i in eachindex(sij)\n",
    "            sij[i] = zeros(Float64, q, q)\n",
    "        end\n",
    "\n",
    "        for i in 1:N, j in 1:N\n",
    "            for m in 1:M\n",
    "                sij[i,j][data[m,i], data[m,j]] += 1\n",
    "            end\n",
    "            sij[i,j] ./= M\n",
    "            #sij[j,i] .= sij[i,j]'\n",
    "        end\n",
    "\n",
    "        return sij  # this gives us the sample frequencies\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using CSV\n",
    "using DataFrames\n",
    "\n",
    "df = DataFrame(CSV.File(\"C:\\\\Users\\\\loren_1hne11w\\\\Documents\\\\Models&Algorithms\\\\data.dat\", delim = \" \", header = false))\n",
    "select!(df, Not( :Column6))\n",
    "xdata = Matrix{Int64}(df)\n",
    "#\"C:\\\\Users\\\\lucia\\\\OneDrive\\\\Desktop\\\\Documenti\\\\Collegio Carlo Alberto\\\\Models and Algorithms\\\\data.dat\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = size(xdata, 1)\n",
    "sij = compute_stats(xdata, M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using ProgressMeter\n",
    "using Distributions\n",
    "\n",
    "function boltzmann_learning(sij::Array{Matrix{Float64}}, J::Array{Matrix{Float64}}; \n",
    "                            λ::Float64 = 0.1, Tmax::Int64 = 500, Teq::Int = 500,\n",
    "                            Twait::Int = 100, dmax::Int64 = 500, εmax::Float64 = 1e-2)\n",
    "\n",
    "    N = size(sij, 1)\n",
    "    q = size(sij[1], 1)\n",
    "\n",
    "    xall = zeros(Int64, dmax, N)\n",
    "    x = sample(1:q, N, replace = true)   # the initial configuration is a random sequence of numbers between 1 and q\n",
    "\n",
    "    sij_model = Array{Matrix{Float64}}(undef, N, N) \n",
    "    for i in eachindex(sij_model)\n",
    "        sij_model[i] = zeros(Float64, q, q)\n",
    "    end\n",
    "\n",
    "    t = 0\n",
    "    ε = 1\n",
    "\n",
    "    ProgressMeter.ijulia_behavior(:clear)\n",
    "    p = ProgressUnknown(\"Learning...\")\n",
    "    while t <= Tmax && ε > εmax     # time associated with learning epochs. \n",
    "                                    # ϵ is a parameter checking whether I have reached convergence or not\n",
    "        t += 1\n",
    "        fill!(xall, 0)\n",
    "        x = sample(1:q, N, replace = true)\n",
    "\n",
    "        for d in 1:Teq  # time associated with the equilibration of the MC        \n",
    "            x = metropolis_ising(x, J)     # we update the initial random configuration using metropolis_ising. The matrix J that is used in the call\n",
    "                                            # of the function is exactly what we want to estimate and that is initialised by the programmer as he\n",
    "                                            # prefers.\n",
    "        end\n",
    "\n",
    "        for d in 1:dmax     # dmax is the number of samples of my Markov Chain that I want to store in order to estimate the J matrix of the model\n",
    "                            # although dmax may be different with respect to the number of samples that we have, it is advisable to use a dmax\n",
    "                            # that is similar to the total number of samples that we have\n",
    "            for d1 in 1:Twait\n",
    "                x = metropolis_ising(x, J)\n",
    "            end\n",
    "            xall[d,:] = x\n",
    "        end \n",
    "\n",
    "        sij_model = compute_stats(xall, dmax)    # now compute_stats takes as input our configurations, hence it returns the frequencies of the model\n",
    "        Δsij = sij .- sij_model\n",
    "        J .= J + λ .* (Δsij)    # J is updated using the gradient acend scheme\n",
    "        \n",
    "        ε = 0.0\n",
    "        for i in eachindex(Δsij)\n",
    "            ε_new = maximum(abs.(Δsij[i]))\n",
    "            if ε_new > ε\n",
    "                ε = ε_new\n",
    "            end\n",
    "        end\n",
    "\n",
    "        #ε = maximum.([abs.(Δsij[i]) for i in eachindex(Δsij)])     # to check whether we have reached convergence or not\n",
    "        if mod(t, 10) == 0\n",
    "            ProgressMeter.next!(p; showvalues = [(:ε , ε)])\n",
    "        end\n",
    "    end\n",
    "\n",
    "    ProgressMeter.finish!(p)\n",
    "\n",
    "    return J, sij_model, ε, xall\n",
    "\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 5\n",
    "q = 4\n",
    "\n",
    "J = Array{Matrix{Float64}}(undef, N, N) \n",
    "for i in eachindex(J)\n",
    "    J[i] = zeros(Float64, q, q)\n",
    "end\n",
    "\n",
    "J, sij_model, ε, xall = boltzmann_learning(sij, J, λ = 0.1, Tmax = 500, εmax = 1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xall"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Up to now we have made inference on the coupling matrix J. \n",
    "\n",
    "The next step consists in capturing the topology of the network of pairwise couplings. Since the coupling matrices J are not straightforward to interpret, we rely on a different tool, the Frobenius norm of each coupling matrix $J_{ij}$.\n",
    "\n",
    "The underlying idea is the following:\n",
    "to assess the topology, we need to map each $q × q$ coupling matrix $J_{ij}$ onto a scalar quantity measuring the coupling strength between the two variables i and j.\n",
    "\n",
    "$$F_{ij} = \\sqrt{\\sum_{a,b}J_{ij}(a,b)^2}$$\n",
    "\n",
    "Once all the Frobenius norms are computed, the \"interacting\" sites can be inferred as those site pairs with the strongest couplings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function Frobenius(J::Array{Matrix{Float64}})\n",
    "    N = size(J,1)\n",
    "    q = size(J[1], 1)\n",
    "\n",
    "    Fij = zeros(Float64, N, N)\n",
    "    for i in 1:N, j in 1:N\n",
    "        for a in 1:q, b in 1:q\n",
    "            Fij[i,j] += (J[i,j][a,b])^2\n",
    "        end\n",
    "        Fij[i,j] = sqrt(Fij[i,j])\n",
    "    end\n",
    "    return Fij\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Fij = Frobenius(J)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using CSV\n",
    "using DataFrames\n",
    "groundtruth = DataFrame(CSV.File(\"groundtruth.dat\", delim = \" \", header = false))\n",
    "F = Matrix{Int64}(groundtruth)\n",
    "f_true=zeros(5,5)\n",
    "for i in 1:5\n",
    "    f_true[i,F[i,1]] = 1\n",
    "    f_true[i,F[i,2]] = 1\n",
    "end\n",
    "f_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using GraphRecipes\n",
    "using NetworkLayout\n",
    "using Plots\n",
    "\n",
    "p1 = graphplot(f_true, edgewidth = abs.(f_true), names = 1:N, method = :chorddiagram, title = \"True graph\")\n",
    "p2 = graphplot(Fij, edgewidth = abs.(Fij), names = 1:N, method = :chorddiagram, title = \"Inferred graph\")\n",
    "\n",
    "plot(p1, p2, aspect_ratio = 1)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The inferred graph clearly shows that the true couplings are correctly inferred by the Boltzmann machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z = Any[]\n",
    "for i in 1:size(Fij,1)\n",
    "    for j in i+1:size(Fij,2)\n",
    "        if Fij[i,j]>0.7\n",
    "            push!(Z, [i,j])\n",
    "        end\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Plots\n",
    "using LaTeXStrings\n",
    "p = Any[]\n",
    "for i in 1:size(Z,1)\n",
    "    g = heatmap(J[Z[i][1], Z[i][2]], xlabel = L\"%$(Z[i][1])\", ylabel = L\"%$(Z[i][2])\", colorbar_title = L\"J_{ij}\")\n",
    "    push!(p,g)\n",
    "end\n",
    "plot(p[1], p[2], aspect_ratio = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(p[3], p[4], aspect_ratio = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uncorrelated = heatmap(J[5,1], xlabel = L\"4\", ylabel = L\"3\", colorbar_title = L\"J\")\n",
    "plot(p[5], uncorrelated, aspect_ratio = 1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is interesting to perform again the estimation of $J$ using a different, Bayesian, approach and then compare the results."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The underlying intuition is the following:\n",
    "\n",
    "The above \"frequentist\" Boltzmann machine is aimed at returning a point estimate of J as a result of a maximization problem. In particular, it performs a gradient ascend method in order to maximize the likelihood function and thus it finds numerically the maximum likelihood estimator (MLE) of J, i.e. the value of J for which, under the assumed statistical model, the observed data have the highest joint probability. To better understand its meaning, it is useful to recall that everytime we perform a ML estimation, we are assuming (as in all frequentist statistical inference procedures) a true generating mechanism, that is to say the existence of a true, but unknown, value of the parameter that has generated the data and that we aim to unveil. Thanks to their straightforward interpretation and their \"good\" properties, MLEs are often used to approximate the true parameter and ML estimation has become a dominant tool to make statistical inference.\n",
    "\n",
    "What we present next requires the switch from a frequentist to a Bayesian point of view.\n",
    "\n",
    "Bayesian statisticians consider the parameter as an actual random variable which, therfore, has its own probability distribution. Loosely speaking, in Bayesian statistics a probability expresses a degree of belief: before performing the experiment, the prior distribution of the parameter encodes the a-priori beliefs about the parameter, i.e. what we expect, for any kind of reason, before observing the data. After collecting the data, Bayes theorem is used to incorporate these information in the prior distribution. The result is the so-called posterior distribution of the considered parameter and it embodies our updated beliefs about the parameter, once evidence is observed. The posterior distribution contains our full knowledge about the parameter.\n",
    "\n",
    "Mathematically, given a prior probability $P(\\theta)$ and a likelihood function $P\\left(\\left\\{x^{(m)}\\right\\}_{i=1}^M | \\,\\theta \\right)$, the posterior distribution of $\\theta$ is, up to a proportionality constant, obtained as\n",
    "\n",
    "$$P\\left(\\theta | \\,\\left\\{x^{(m)}\\right\\}_{i=1}^M\\right) \\quad \\propto \\quad P(\\theta) \\, P\\left(\\left\\{x^{(m)}\\right\\}_{i=1}^M | \\,\\theta \\right) $$\n",
    "\n",
    "The posterior distribution is at the heart of Bayesian inference. Indeed, depending on the situations, meaningful statistics of the parameter can be derived from it and used as estimates of the parameter itself. To be more precise, Bayesian estimation methods are based on the minimization of the posterior risk with respect to a specified loss function. For instance, for a quadratic loss, an absolute error loss or the 0-1 loss function, the Bayes estimator is given, respectively, by the posterior mean, median and mode.\n",
    "\n",
    "To be more complete, let us mention the fact that dealing with the 0-1 loss function is actually trickier. Everything works fine in the discrete case, whereas in the continuous one it needs to be expressed in terms of the Dirac delta distribution (and thus it would not be properly a function anymore)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the particular situation we are considering, we aim at modifying the Boltzmann machine so that it would not return the MLE of our parameter $J$, but an estimate that \"exploits\" its posterior distribution. As we have shortly argued above, there is not a unique choice for the estimator to be used, nevertheless the maximum a posteriori (MAP) estimate appeared to us as the most natural one.\n",
    "\n",
    "The MAP estimate is, by definition, the value that maximizes the posterior distribution (its mode):\n",
    "$$J_{MAP} = \\argmax_{J} P\\left(J \\, | \\,\\left\\{x^{(m)}\\right\\}_{i=1}^M\\right)$$\n",
    "\n",
    "Its interpretation is clear: it corresponds to the \"point\" in the parameter space with the \"highest probability of occurence\", given both the observed data and prior information.\n",
    "\n",
    "It is also interesting (and easy to observe) that if the prior distribution over the parameter is chosen to be uniform, then the MAP estimate actually coincides with the MLE. Generally a uniform prior distribution is interpreted as an uninformative prior distribution, meaning that it is used when no prior information is available or to prevent our prior beliefs from affecting the results. As a consequence the posterior distribution will be totally specified by the likelihood function and the MLE will be retrieved. This provides further support to our estimation choice: the previous estimation procedure intrinsically emerges as a special case (the one corresponding to a uniform prior distribution) of the method we are going to present.\n",
    "\n",
    "As a final remark, we can say that the MAP estimate can be considered a \"Bayesian generalization of the MLE\", since it corresponds to the mode of an augmented optimization objective which incorporates the prior distribution (that quantifies the a-priori additional information available)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given everything we have said, let us design the new Boltzmann machine learning scheme. Exactly as before, we use an iterative update of $J$ based on a gradient ascend method, hence we need to compute the gradient of the objective function we want to maximizes:\n",
    "\n",
    "$$\\begin{aligned}\n",
    "P\\left(J \\, | \\,\\left\\{x^{(m)}\\right\\}_{i=1}^M\\right) = \\quad \\propto \\quad &P(J) \\, P\\left(\\left\\{x^{(m)}\\right\\}_{i=1}^M | \\,J \\right)\\\\ & e^{-\\lambda \\sum_{a,b,i,j}\\lvert J_{ij}(a,b) \\rvert} \\, \\prod_m\\frac{1}{Z}e^{\\sum_{i,j}\\sum_{a,b}J_{ij}(a,b)\\delta_{(x_i^{(m)},a)}\\delta_{(x_j^{(m)},b)}}\n",
    "\\end{aligned}$$\n",
    "\n",
    "(note that it is concave so it has only one maximum and the gradient ascend method can be performed)\n",
    "\n",
    "It is convenient to take its logarithm and divide everything by M:\n",
    "$$ (\\star) \\quad \\frac{1}{M} log\\left(P\\left(J \\, | \\,\\left\\{x^{(m)}\\right\\}_{i=1}^M\\right)\\right) = - \\frac{\\lambda}{M}\\sum_{a,b,i,j} \\lvert J_{ij}(a,b) \\rvert + {\\frac{1}{M}} \\sum_{i,j}\\sum_{a,b}\\sum_mJ_{ij}(a,b)\\delta_{(x_i^{(m)},a)}\\delta_{(x_j^{(m)},b)} - \\log\\left[ Z\\left( J\\right)\\right]$$\n",
    "\n",
    "We can now derive the gradient:\n",
    "\\begin{align}\n",
    "\\frac{\\partial (\\star) }{\\partial J_{i,j}(a,b)} & = {-\\frac{\\lambda}{M}} sign\\left( J_{i,j}(a,b) \\right) + {\\frac{1}{M}} \\sum_{m} \\delta_{(x_i^{(m)},a)}\\delta_{(x_j^{(m)},b)} - \\frac{1}{Z\\left( J\\right)} \\sum_{\\boldsymbol{x}} \\delta_{(x_i^{(m)},a)}\\delta_{(x_j^{(m)},b)} e^{\\sum_{i,j}\\sum_{ab}J_{ij}(a,b)\\delta_{(x_i^{(m)},a)}\\delta_{(x_j^{(m)},b)}} \\\\\n",
    "& = {-\\frac{\\lambda}{M}} sign\\left( J_{i,j}(a,b) \\right) + { < \\delta_{(x_i,a)} \\delta_{(x_j,b)} >_{\\mathrm{data}} -  < \\delta_{(x_i,a)} \\delta_{(x_j,b)} >_{\\mathrm{model}}}\n",
    "\\end{align}\n",
    "\n",
    "The Boltzmann machine learning scheme can therefore being updated as follows:\n",
    "$$J_{i,j}^{t+1}(a,b) \\leftarrow J_{i,j}^{t}(a,b) \\, {-\\frac{\\lambda*\\lambda_{J}}{M}} sign\\left( J_{i,j}(a,b) \\right) + \\lambda_{J} \\left[ < \\delta_{(x_i,a)} \\delta_{(x_j,b)} >_{\\mathrm{data}} -  < \\delta_{(x_i,a)} \\delta_{(x_j,b)} >_{\\mathrm{model}\\left(t \\right)} \\right] $$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a matter of notation, we will denote the parameter $\\lambda$ of the prior distribution as $\\lambda_{prior}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using ProgressMeter\n",
    "using Distributions\n",
    "\n",
    "function boltzmann_learning_MAP(sij::Array{Matrix{Float64}}, J::Array{Matrix{Float64}}; \n",
    "                            λ::Float64 = 0.1, λ_prior::Float64 = 0.1, Tmax::Int64 = 500, Teq::Int = 500,\n",
    "                            Twait::Int = 100, dmax::Int64 = 500, εmax::Float64 = 1e-2)\n",
    "\n",
    "    N = size(sij, 1)\n",
    "    q = size(sij[1], 1)\n",
    "\n",
    "    xall = zeros(Int64, dmax, N)\n",
    "    x = sample(1:q, N, replace = true)   # the initial configuration is a random sequence of numbers between 1 and q\n",
    "\n",
    "    sij_model = Array{Matrix{Float64}}(undef, N, N) \n",
    "    for i in eachindex(sij_model)\n",
    "        sij_model[i] = zeros(Float64, q, q)\n",
    "    end\n",
    "\n",
    "    t = 0\n",
    "    ε = 1\n",
    "\n",
    "    ProgressMeter.ijulia_behavior(:clear)\n",
    "    p = ProgressUnknown(\"Learning...\")\n",
    "    while t <= Tmax && ε > εmax     # time associated with learning epochs. \n",
    "        t += 1\n",
    "        fill!(xall, 0)\n",
    "        x = sample(1:q, N, replace = true)\n",
    "\n",
    "        for d in 1:Teq  # time associated with the equilibration of the MC        \n",
    "            x = metropolis_ising(x, J)     # we update the initial random configuration using metropolis_ising.\n",
    "        end\n",
    "\n",
    "        for d in 1:dmax     # dmax is the number of samples of my Markov Chain that I want to store in order to estimate the J matrix of the model\n",
    "                            # although dmax may be different with respect to the number of samples that we have, it is advisable to use a dmax\n",
    "                            # that is similar to the total number of samples that we have\n",
    "            for d1 in 1:Twait\n",
    "                x = metropolis_ising(x, J)\n",
    "            end\n",
    "            xall[d,:] = x\n",
    "        end \n",
    "\n",
    "        sij_model = compute_stats(xall, dmax)    # now compute_stats takes as input our configurations, hence it returns the frequencies of the model\n",
    "        Δsij = sij  .- sij_model \n",
    "        J .= J + λ .* (Δsij)    # J is updated using the gradient acend scheme\n",
    "        for i in 1:N, j in 1:N\n",
    "            J[i,j] = J[i,j] - (λ_prior*λ)/dmax .* sign.(J[i,j])\n",
    "        end\n",
    "        \n",
    "        ε = 0.0\n",
    "        for i in eachindex(Δsij)\n",
    "            ε_new = maximum(abs.(Δsij[i]))\n",
    "            if ε_new > ε\n",
    "                ε = ε_new\n",
    "            end\n",
    "        end\n",
    "\n",
    "        if mod(t, 10) == 0\n",
    "            ProgressMeter.next!(p; showvalues = [(:ε , ε)])\n",
    "        end\n",
    "    end\n",
    "\n",
    "    ProgressMeter.finish!(p)\n",
    "\n",
    "    return J, sij_model, ε, xall\n",
    "\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 5\n",
    "q = 4\n",
    "\n",
    "J_MAP = Array{Matrix{Float64}}(undef, N, N) \n",
    "for i in eachindex(J_MAP)\n",
    "    J_MAP[i] = zeros(Float64, q, q)\n",
    "end\n",
    "\n",
    "J_MAP, sij_model, ε, xall = boltzmann_learning_MAP(sij, J_MAP, λ = 0.1, λ_prior = 0.1, Tmax = 500, εmax = 1e-2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As before, we detect the \"interacting\" variables by means of the Frobenius norm of each coupling matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Fij_MAP = Frobenius(J_MAP)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is easy to verify that the just computed coupling pattern fit the previous one. Indeed, even if the entities of the norms may be differ a bit, the detected contacting (or interacting) site pairs correspond exactly.\n",
    "\n",
    "Note that this is also important to target the coherence of our results: at least nothing seems to suggest that our procedures are wrong.\n",
    "\n",
    "Before continuing the comparison of the two strategies - the frequentist and the Bayesian one - we target rapidly the choice of the parameter $\\lambda_{prior}$ of the prior distribution. Loosely speaking, as the sample size increases, the likelihood becomes more and more relevant in determining the posterior distribution, however an inappropriate prior distribution may dramatically slow down the convergence or even lead to inconsistent results. Therefore, in real-life applications, it is preferable to determine it by means of cross-validation.\n",
    "\n",
    "To adress our particular case it may be useful to try to understand the meaning of the prior distribution.\n",
    "\n",
    "We can easily recognize, in its exponential, the L1-norm of the parameter coupling matrix $J$. Now, since our aim is to maximize the posterior distribution, the chosen $L_1$ prior imposes a sparse solution by adding a \"penalty\" that increases quickly near the origin, with a linear slope. In other words, because the prior is an exponentially\n",
    "decaying function, in the course of inference it favors matrices $J$ with small $L_1-norms$ and penalises $J$'s with large $L_1-norms$, . More generally, this prior may be seen as a regulariser: it penalises large parameter values that may arise through maximization of the log-likelihood.\n",
    "\n",
    "Actually, something more interesting can be said: if we consider the whole class of $L_p-norm$ priors\n",
    "\n",
    "$$p(J) = e^{-\\lambda \\, \\lvert\\lvert J \\rvert\\rvert_p} $$\n",
    "\n",
    "it can be proven that the $L_1$ prior is the only one that favours sparsity while preserving the concavity of the log-likelihood into the log-posterior.\n",
    "\n",
    "In our case, we have been explicitely asked to choose a small $\\lambda_{prior}$ in the prior distribution. Heuristically, we may understand this request by noticing that if $\\lambda_{prior}$ is large, then the prior distribution returns values very close to zero (for every J whose norm 1 is different from zero). This may result in a posterior distribution that is \"too flat\" and depends only poorly on the likelihood. In other words we can say that the model is overconstrained by the prior, and has not enough power to account for the true distribution of the data.\n",
    "\n",
    "Conversely, choosing a $\\lambda_{prior}$ that is too small makes almost irrelevant the presence of the prior distribution (indeed in the limit $\\lambda_{prior} \\to 0$ the prior distribution becomes closer and closer to a uniform one). As a consequence we may say that, for low $\\lambda_{prior}$ values, the inferred model overfits the details of the data set and this is actually one of the things aimed to avoid using a Bayesian framework.\n",
    "\n",
    "For these reasons we decided to choose a \"good compromise\" between these extreme behaviors: $\\lambda_{prior} = 0.1$ appears to us as a good choice.\n",
    "\n",
    "Below we tried to re-run the *boltzmann_learning_MAP* function for different values of $\\lambda_{prior}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "λ_prior = 0.1 #10.0, 1.0, 0.01\n",
    "q = 4\n",
    "fill!(J_MAP, zeros(Float64, q,q))\n",
    "J_MAP, _ = boltzmann_learning_MAP(sij, J_MAP, λ = 0.1, λ_prior = λ_prior, Tmax = 500, εmax = 1e-2)\n",
    "\n",
    "Fij_MAP = Frobenius(J_MAP)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected for large values of $\\lambda_{prior}$, the Boltzmann machine learning scheme does not seem to work properly. Indeed, by looking at the corresponding Frobenius norms, we can observe that the entries of the inferred coupling matrix (and so their Frobenius norms) are eccesively drawn toward zero. This suits perfectly our previus interpretation: for large values of $\\lambda_{prior}$ the prior is over-weighted and, consequently, the prior is over-constrained. This lead to a very sparse coupling matrix. Nevertheless we are still able to detect the strongest couplings.\n",
    "\n",
    "For what concerns small - but still sufficiently different from zero - values of $\\lambda_{prior}$ (such as $\\lambda_{prior} = 0.5, \\, 0.1, \\, 0.01$) we found consistency with the previous method.\n",
    "\n",
    "This is important since it gives us a further check of the previous results."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now proceed with our comparison: our current aim is to tackle the efficiency of the two approaches.\n",
    "\n",
    "More precisely, since we are mainly interested in detecting the \"interacting variables\" - i.e. the pairs of variables that score high in the Frobenius norm matrix - we appreciate the efficiency of the methods by looking at \"how strong the couplings of the interacting variables are\". In addition, it is also interesting to check wheter the \"gap\" between the Frobenius norms of the most coupled and less coupled variables remains sufficiently large.\n",
    "\n",
    "To do so we re-run the Boltzmann machine algorithms letting the number of iterations performed by the Boltzmann learning schemas vary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tmax_range = [100, 500, 1000, 2500, 5000]\n",
    "Fij_Tmax = Vector{Matrix{Float64}}(undef, length(Tmax_range))\n",
    "Fij_MAP_Tmax = Vector{Matrix{Float64}}(undef, length(Tmax_range))\n",
    "\n",
    "for (i, Tmax) in enumerate(Tmax_range)\n",
    "    fill!(J, zeros(Float64, q,q))\n",
    "    fill!(J_MAP, zeros(Float64, q,q))\n",
    "\n",
    "    J, _ = boltzmann_learning(sij, J, λ = 0.1, Tmax = Tmax, εmax = 1e-2)\n",
    "    J_MAP, _ = boltzmann_learning_MAP(sij, J_MAP, λ = 0.1, λ_prior = 0.1, Tmax = Tmax, εmax = 1e-2)\n",
    "\n",
    "    Fij_Tmax[i] = Frobenius(J)\n",
    "    Fij_MAP_Tmax[i] = Frobenius(J_MAP)   \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Tmax = \", Tmax_range[1])\n",
    "\n",
    "display(Fij_Tmax[1])\n",
    "display(Fij_MAP_Tmax[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Tmax = \", Tmax_range[2])\n",
    "\n",
    "display(Fij_Tmax[2])\n",
    "display(Fij_MAP_Tmax[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Tmax = \", Tmax_range[3])\n",
    "\n",
    "display(Fij_Tmax[3])\n",
    "display(Fij_MAP_Tmax[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Tmax = \", Tmax_range[4])\n",
    "\n",
    "display(Fij_Tmax[4])\n",
    "display(Fij_MAP_Tmax[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Tmax = \", Tmax_range[5])\n",
    "\n",
    "display(Fij_Tmax[5])\n",
    "display(Fij_MAP_Tmax[5])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all we observe that looking at the different matrices we can find consistency between the two methods. Indeed in each of the above matrices we can easily distinguish the \"true-interacting\" variables.\n",
    "\n",
    "Moreover we can argue that, if the number of iterations of the Boltzmann learning remains relatively small, then it seems that the MLE of $J$ corresponds to a \"more coupled\" configuration than the MAP estimator. Once the number of iterations grows, however, the difference between the two matrices tends to disaappear and, therefore, we can say that the second method starts to learn at a faster rate. \n",
    "\n",
    "These results may be explained by recalling the interpretation of the prior distribution as a regulariser. Since it tends to penalize large parameter values - that may arise through maximisation of the log-likelihood - and favors sparsification of $J$, it seems reasonable to have a MAP estimator that has entries closer to zero than those of the MLE.\n",
    "\n",
    "On the other hand, as the number of iterations gets larger, it may happen that the presence of the regulariser actually makes the method more stable and hence better in targeting the strongly coupled variables. Another thing to keep into account and that may be the fact that the \"standard\" Boltzmann machine may have already reached a point that is close to the maximum. This latter comment is heuristic and a bit controversial since the Boltzmann machine does not stop because the threshold $\\epsilon$ has been reached and thus the gradient ascend method still \"moves $J$ around\" properly.  \n",
    "\n",
    "In any case, we emphasize the fact the results of the two approaches are coherent: we always observe a meaningfully large gap among the strong and weak couplings (and the detected strongest-coupled variables are always the same).\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to repeat the inference changing the number of configurations $M$ we recall the function that defines the Boltzmann machine and modify it restraining the number of observations from the file \"data.dat\". This procedure is actually straighforward given the definition that we gave to the function \"compute_stats\", in fact we just need to choose the number \"M\" as we want and then run the Boltzmann machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = [1,10,100,500,1000]\n",
    "sij_new = Any[]\n",
    "\n",
    "for i in 1:size(M,1)\n",
    "    s = compute_stats(xdata, M[i])\n",
    "    push!(sij_new, s)\n",
    "end\n",
    "\n",
    "J_new = Any[]\n",
    "sij_model_new = Any[]\n",
    "ε_new = Any[]\n",
    "xall_new = Any[]\n",
    "Fij_new = Any[]\n",
    "\n",
    "J0 = Array{Matrix{Float64}}(undef, N, N)\n",
    "    for i in eachindex(J)\n",
    "        J0[i] = zeros(Float64, q, q)\n",
    "    end\n",
    "\n",
    "for j in 1:size(sij_new,1)\n",
    "\n",
    "    fill!(J0, zeros(Float64, q,q))\n",
    "    \n",
    "    a, b, c, d = boltzmann_learning(sij_new[j], J0, λ = 0.1, Tmax = 500, εmax = 1e-2)\n",
    "    e = Frobenius(a)\n",
    "    push!(J_new, a)\n",
    "    push!(sij_model_new, b)\n",
    "    push!(ε_new, c)\n",
    "    push!(xall_new, d)\n",
    "    push!(Fij_new, e)\n",
    "end\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using GraphRecipes\n",
    "using NetworkLayout\n",
    "using Plots\n",
    "\n",
    "p1 = graphplot(f_true, edgewidth = abs.(f_true), names = 1:N, method = :chorddiagram, title = \"True graph\")\n",
    "p2 = graphplot(Fij_new[1], edgewidth = abs.(Fij_new[1]), names = 1:N, method = :chorddiagram, title = \"Inferred graph\")\n",
    "\n",
    "plot(p1, p2, aspect_ratio = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p3 = graphplot(Fij_new[2], edgewidth = abs.(Fij_new[2]), names = 1:N, method = :chorddiagram, title = \"Inferred graph\")\n",
    "\n",
    "plot(p1, p3, aspect_ratio = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p4 = graphplot(Fij_new[3], edgewidth = abs.(Fij_new[3]), names = 1:N, method = :chorddiagram, title = \"Inferred graph\")\n",
    "\n",
    "plot(p1, p4, aspect_ratio = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p5 = graphplot(Fij_new[4], edgewidth = abs.(Fij_new[4]), names = 1:N, method = :chorddiagram, title = \"Inferred graph\")\n",
    "\n",
    "plot(p1, p5, aspect_ratio = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p6 = graphplot(Fij_new[5], edgewidth = abs.(Fij_new[5]), names = 1:N, method = :chorddiagram, title = \"Inferred graph\")\n",
    "\n",
    "plot(p1, p6, aspect_ratio = 1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By this comparison it becomes clear how much the number of observations is crucial in the inference process. Indeed we can see that while M is less than 500 observation it is almost impossible to detect the actual couplings, while if M is sufficiently large the Boltzamann machine allows us to spot them. It is also worth to note that for M greater than 1000 the inference process does not improve if M increases.  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the main problems of MCMC is that the samples are not independent. Therefore usually the collection of samples is done waiting a time interval $\\Delta t$ that brings independece between samples. In order to quantify this correlation we estimate the autocorrelation function associated to the Markov chain that fetures the Bolzmann Machine. We recall that the autocorrelation function has the form:\n",
    "\\begin{align}\n",
    "\\gamma(r) = \\frac{\\mathbb{E}[(x^{(t)}-\\mu_t)(x^{(s)}-\\mu_s)]}{\\sqrt {\\sigma_t^2\\sigma_s^2}}\n",
    "\\end{align}\n",
    "Because of the stationarity of the Markov chain we get:\n",
    "\\begin{align}\n",
    "\\gamma(r) = \\frac{\\mathbb{E}[(x^{(t)}-\\mu)(x^{(t+r)}-\\mu)]}{\\sigma^2}\n",
    "\\end{align} \n",
    "As seen in the lecture an unbiased Monte Carlo estimator of $\\gamma$ is given by:\n",
    "\\begin{align}\n",
    "\\hat{\\gamma}_n(r) = \\frac{\\frac{1}{n-r}\\sum_{k=1}^{n-r}(\\hat{x}^{(k)}-\\hat{\\mu}_n)(\\hat{x}^{(k+r)}-\\hat{\\mu}_n)}{\\frac{1}{n}\\sum_{k=1}^{n}(\\hat{x}^{(k)}-\\hat{\\mu}_n)^2}\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function autocorrelation(x::Array{Float64}, R::Int64)\n",
    "    n = lenght(x)\n",
    "    μ = sum(x) / n\n",
    "    gamma = [0.0 for i in 1:R]\n",
    "\n",
    "    for r in 1:R\n",
    "        for i in 1:(n-r+1)\n",
    "            gamma[r] += (x[i] - μ) * (x[i+r-1] - μ) / (n - r + 1)\n",
    "        end\n",
    "    end\n",
    "\n",
    "    var = gamma[1]\n",
    "    gamma ./= var\n",
    "end"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We well vary the couples $(M,T_{wait})$ with the following values:\n",
    "- $M = (1,10,100,500,1000)$\n",
    "- $T_{wait} = (1,10,50,100,250)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Tw = [1,10,50,100,200]\n",
    "Xall = Array{Vector{Float64}}(undef, size(M), size(Tw))\n",
    "\n",
    "for m in 1:size(M,1)\n",
    "    for t in 1:size(Tw,1)\n",
    "        Xall[m,t] = boltzmann_learning(compute_stats(xdata, M[m]), J, λ = 0.1, Tmax = 500, Twait = Tw[t], εmax = 1e-2)[4]\n",
    "    end\n",
    "end\n",
    "\n",
    "#R has to be choosen\n",
    "Ac = Array{Vector{Float64}}(undef, size(M), size(Tw))\n",
    "\n",
    "for m in 1:size(M,1)\n",
    "    for t in 1:size(Tw,1)\n",
    "        Ac[m,t] = autocorrelation(Xall[m,t], R)\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.8.5",
   "language": "julia",
   "name": "julia-1.8"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
